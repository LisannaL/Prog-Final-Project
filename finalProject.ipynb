{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Using Machine Learning Techniques in <br> the Detection of Fake News </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='font-weight:normal'><center> Spring Term Project, <b> Lisanna Lehes </b> </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> \n",
    "Universidad de Huelva <br>\n",
    "Facultad de CC. Experimentales <br>\n",
    "Grado en Química <br>\n",
    "Computational Chemistry\n",
    " </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Aim of the project:</b> to create a machine learning model that would help detect fake news using Scikit-learn library and Passive Agression Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "df = pd.read_csv('/Users/Lisanna/Desktop/fake_news/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returning the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Converting the '0's and '1's to 'FAKE' and 'TRUE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‘0’ for RELIABLE article <br>\n",
    "‘1’ for FAKE NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a group of rows and columns by label\n",
    "df.loc[(df['label'] == 1) , ['label']] = 'FAKE'\n",
    "df.loc[(df['label'] == 0), ['label']] = 'REAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  FAKE  \n",
       "1  Ever get the feeling your life circles the rou...  REAL  \n",
       "2  Why the Truth Might Get You Fired October 29, ...  FAKE  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...  FAKE  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...  FAKE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Splitting the dataset into test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    REAL\n",
       "2    FAKE\n",
       "3    FAKE\n",
       "4    FAKE\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.label\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    10413\n",
       "REAL    10387\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the downloaded dataset into two subsets, 70% of the entries\n",
    "will be used to train the model and the rest (30%) to test the model’s predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split arrays or matrices into random train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'].values.astype('str'), labels, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random_state parameter may be provided to control the random number generator used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TfidfVectorizer__ uses stop words from the English language. <br>\n",
    "The number of times a word appears in a document is its __Term Frequency__. <br> A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__max_df__ --> ignores terms that appear in more than 70% of the documents --> used for terms that appear too frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fitting and transfroming the test and training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __transform()__ : parameters generated from fit() method,applied upon model to generate transformed data set.\n",
    "\n",
    "* __fit_transform()__ : combination of fit() and transform() api on same data set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Initializing PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "# Passive: if correct classification, keep the model; \n",
    "# Aggressive: if incorrect classification, update to adjust to this misclassified example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_classifier = PassiveAggressiveClassifier(max_iter = 50)\n",
    "pa_classifier.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__max_iter__ --> Maximum number of iterations of the k-means algorithm for a single run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Predicting and calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pa_classifier.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9610576923076923\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.106%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round(score*100, 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the accuracy of the model can be seen when it was conducting its tests. <br> Whereas we know the model's accuracy, we don't know the number of successful predictions/failures. <br> Therefore, we are now going to build a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Building a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3004,  108],\n",
       "       [ 135, 2993]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred, labels = ['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Results:__ <br>\n",
    "* The model successfully predicted 3001 positives. (Is fake and is predicted as fake)\n",
    "* The model successfully predicted 2998 negatives. (Is real and is predicted as real)\n",
    "* The model predicted 111 false positives. (Real news were considered as fake)\n",
    "* The model predicted 130 false negatives. (Fake News were considered as real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we could compute the __F1-score__. <br> \n",
    "__F1 score__ is used to measure a test’s accuracy, therefore, an F-score is considered perfect when it's 1 , while the model is a total failure when it's 0.<br>  A good __F1-score__ means that you have low false positives and low false negatives,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 2TP / (2TP + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613967643761012\n"
     ]
    }
   ],
   "source": [
    "F1 = 2*3001 / (2*3001 + 130 + 111)\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.96      0.97      0.96      3112\n",
      "        REAL       0.97      0.96      0.96      3128\n",
      "\n",
      "    accuracy                           0.96      6240\n",
      "   macro avg       0.96      0.96      0.96      6240\n",
      "weighted avg       0.96      0.96      0.96      6240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred, labels = ['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The aim of part II is to experiment on the model by adding and substracting some variables and to see if the accuracy score is affected by it e.g.:__\n",
    "\n",
    "1. Build a model that would take in __only__ the title of a news article and then predict if it's fake or real.\n",
    "\n",
    "2. Build a model that would take in __both__, the __text__ of the article and the __title__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Experimenting with the title of news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_2 = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title, x_test_title ,y_train_title ,y_test_title = train_test_split(df['title'].values.astype('str'), labels_2, test_size=0.3, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_title = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "#Fit and transform train set, transform test set\n",
    "\n",
    "tfidf_train_title = tfidf_vectorizer_title.fit_transform(x_train_title) \n",
    "tfidf_test_title = tfidf_vectorizer_title.transform(x_test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_classifier_title = PassiveAggressiveClassifier(max_iter = 50)\n",
    "pa_classifier_title.fit(tfidf_train_title, y_train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.927724358974359\n"
     ]
    }
   ],
   "source": [
    "y_pred_title = pa_classifier_title.predict(tfidf_test_title)\n",
    "score_title = accuracy_score(y_test_title, y_pred_title)\n",
    "print('Accuracy:', score_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.772%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round(score_title*100, 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2919,  193],\n",
       "       [ 258, 2870]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_title, y_pred_title, labels = ['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Results:__\n",
    "* The model predicted 2929 positives. (Is fake and were considered fake)\n",
    "* The model predicted 2874 negatives. (Is real and were considered real)\n",
    "* The model predicted 183 false positives. (Real news wereconsidered as fake)\n",
    "* The model predicted 254 false negatives. (Fake news were considered as real)\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.92      0.94      0.93      3112\n",
      "        REAL       0.94      0.92      0.93      3128\n",
      "\n",
      "    accuracy                           0.93      6240\n",
      "   macro avg       0.93      0.93      0.93      6240\n",
      "weighted avg       0.93      0.93      0.93      6240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test_title, y_pred_title, labels = ['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prediction model with 2 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I am trying to detect fake news by building a model that would have __two variables__ - __text of the article__ and __title__ - and see if the <br> accuracy score is affected by it (whether it builds a better model or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_3 = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampledata = df[['text', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.2 GiB for an array with shape (20800, 2) and data type <U142961",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-020b3211a4ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampledata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 22.2 GiB for an array with shape (20800, 2) and data type <U142961"
     ]
    }
   ],
   "source": [
    "#x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(sampledata.values.astype('str'), labels_3, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer_2 = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "#Fit and transform train set, transform test set\n",
    "\n",
    "#tfidf_train_2 = tfidf_vectorizer_2.fit_transform(x_train_2) \n",
    "#tfidf_test_2 = tfidf_vectorizer_2.transform(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pa_classifier_2 = PassiveAggressiveClassifier(max_iter = 50)\n",
    "#pa_classifier_2.fit(tfidf_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_2 = pa_classifier_2e.predict(tfidf_test_2)\n",
    "#score_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "#print('Accuracy:', score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Accuracy: {round(score_2*100, 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_test_2, y_pred_2, labels = ['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.classification_report(y_test_2, y_pred_2, labels = ['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The aim of the third part is to try to implement a GUI and test the original model with other news articles (not from the Kaggle dataset)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_article(text):\n",
    "    print(text)\n",
    "    vector = tfidf_vectorizer.transform([text])\n",
    "    print(vector)\n",
    "    result = pa_classifier.predict(vector)\n",
    "    result1 = pa_classifier.decision_function(vector)\n",
    "    print(result)\n",
    "    print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON – President Donald Trump drew fire from critics Saturday for sprinkling racially divisive stereotypes throughout his remarks at a high-profile campaign rally in Tulsa as the nation is grappling with racism and police misconduct. \n",
      "\n",
      "Speaking after protests and unrest broke out in cities across the nation following the death of George Floyd last month, Trump described violent protesters he claimed had forced the cancellation of a separate outdoor campaign event in Tulsa as \"thugs.\" He used the term \"kung flu\" to describe the coronavirus. And he blasted the removal of Confederate statues, arguing that a \"left wing mob\" wanted to \"vandalize our history.\"\n",
      "\n",
      "At one point during his remarks, as he sought to brush aside calls from some on the left to defund police departments, Trump painted a scene of a \"tough hombre\" who he described as \"breaking into the window of a young woman whose husband is away.\"   \n",
      "\n",
      "\"And you call 911 and they say, 'I'm sorry, this number is no longer working,'\" Trump said.   The president's remarks came as demonstrators continued to gather in many cities to protest the death of Floyd, a Black man whose neck was pinned under the knee of a white Minneapolis police officer for nearly nine minutes. Violence erupted in many cities after Floyd's death, but protests were largely peaceful nationwide.\n",
      "\n",
      "Tulsa rally: Trump said he wanted to 'slow the testing down' on coronavirus\n",
      "\n",
      "Trump's gamble: Tulsa rally is aimed at rebooting but it holds huge risks\n",
      "\n",
      "\"Trump just completed the racism trifecta in a three-minute span,\" a Democratic National Committee social media account posted during the rally, the president's first return to the campaign trail since the coronavirus struck the nation in force this spring. \n",
      "\n",
      "\"121,000 Americans are dead,\" Sen. Tammy Duckworth, D-Ill., tweeted after the rally. \n",
      "\n",
      "\"Donald Trump’s response is to make racist jokes.\"\n",
      "\n",
      "The rally ran into trouble on racial issues before it even began. The campaign had to reschedule after it initially set the event for Juneteenth, the holiday celebrating the end of slavery in the United States. Trump has also faced a backlash for holding the rally in a city that was home to one of the worst racial attacks in U.S. history.\n",
      "\n",
      "He then claimed in an interview with the Wall Street Journal that \"nobody had ever heard\" of the Juneteenth holiday before the controversy erupted. \n",
      "\n",
      "Trump never mentioned Floyd's name during his remarks Saturday night. Nor did he mention the Juneteenth holiday on Friday that prompted his campaign to reschedule its initial date for the rally. He also did not mention the 1921 Tulsa race massacre, in which a white mob killed an estimated 300 Black Americans while destroying homes and businesses in a once-thriving district known as the Black Wall Street. \n",
      "\n",
      "Trump has drawn fire for many past comments on race, including when he said there were \"fine people on both sides\" at a white nationalist rally in Charlottesville, Virginia, in 2017, when he described members of the violent MS-13 gang as \"animals\" or reportedly called Haiti, El Salvador and African nations \"shithole countries.\"\n",
      "\n",
      "But Trump's remarks on Saturday fell at a particularly sensitive moment in the USA, when the Floyd killing has forced a reexamination not only of police use of force practices but also charges of underlying racism in the nation's criminal justice system. \n",
      "\n",
      "Polls suggest the perception of police has fallen in recent weeks. Among white Americans – a group from which Trump enjoyed broad support in 2016 – those who had a very favorable or somewhat favorable view of police dropped to 61% from 72% the previous week in a survey from the Democracy Fund + UCLA Nationscape Project. On the other hand, Trump offered little in the way of concrete policies he would pursue in a second term to benefit Black voters. And he repeatedly embraced language and themes that groups advocating for racial justice have decried. \n",
      "\n",
      "\"The unhinged left wing mob is trying to vandalize our history, desecrating our monuments, our beautiful monuments, tear down our statues and punish, cancel and persecute anyone who does not conform to their demands for absolute and total control, we're not conforming,\" Trump said Saturday about protesters forcibly removing statues and other symbols of the Confederacy. \n",
      "\n",
      "Democrats and other critics on social media also blasted Trump for using the term \"kung flu\" to describe coronaviurs. White House senior adviser Kellyanne Conway disputed reports this year that the term was used inside the West Wing. A CBS News reporter said an unnamed official used the phrase in her presence. \n",
      "\n",
      "At the time, Conway described the term as \"highly offensive,\" said \"of course it's wrong\" and asked reporters to identify who the official was. \"I'd like to know who they are,\" Conway told reporters outside the White House in March. \"You can't just say that and not name them. Tell us who it was.\" \n",
      "\n",
      "Public health officials have discouraged terms that associate a pandemic with a place. Trump had frequently called the coronavirus the \"Chinese virus\" in the early weeks of the pandemic as a way to blame Beijing for its handling of the crisis there.\n",
      "  (0, 130289)\t0.02338682560053978\n",
      "  (0, 129941)\t0.01486037998131645\n",
      "  (0, 129194)\t0.025524656315018712\n",
      "  (0, 129011)\t0.02958970667855769\n",
      "  (0, 128918)\t0.020776080759963064\n",
      "  (0, 128736)\t0.023963137608302494\n",
      "  (0, 128277)\t0.09634855556532906\n",
      "  (0, 128231)\t0.03503088168555201\n",
      "  (0, 127739)\t0.10957057829646229\n",
      "  (0, 127422)\t0.0248505738829645\n",
      "  (0, 127080)\t0.045730762216012244\n",
      "  (0, 127064)\t0.017895239415833007\n",
      "  (0, 126852)\t0.030860112452883063\n",
      "  (0, 126677)\t0.019130788340972822\n",
      "  (0, 126493)\t0.04744283303595744\n",
      "  (0, 126366)\t0.049535566182615925\n",
      "  (0, 125867)\t0.024305276784640773\n",
      "  (0, 125289)\t0.04316281323498236\n",
      "  (0, 125249)\t0.03170731696201836\n",
      "  (0, 125209)\t0.058926617087866846\n",
      "  (0, 125206)\t0.026127199222685582\n",
      "  (0, 125004)\t0.0248839549314386\n",
      "  (0, 123709)\t0.1283852626249103\n",
      "  (0, 123196)\t0.021641773769877082\n",
      "  (0, 123161)\t0.05500243804520473\n",
      "  :\t:\n",
      "  (0, 12014)\t0.038560773002996616\n",
      "  (0, 11576)\t0.020042364898133266\n",
      "  (0, 10700)\t0.02483394043130435\n",
      "  (0, 10320)\t0.034306741604613326\n",
      "  (0, 10111)\t0.020005116130973558\n",
      "  (0, 10081)\t0.03217651040682895\n",
      "  (0, 9401)\t0.034832098481396415\n",
      "  (0, 7928)\t0.036089210890708844\n",
      "  (0, 7218)\t0.06265465323695892\n",
      "  (0, 5728)\t0.032086208514368345\n",
      "  (0, 5308)\t0.03239166353729528\n",
      "  (0, 5086)\t0.04373003519190877\n",
      "  (0, 5073)\t0.029526234018791363\n",
      "  (0, 4148)\t0.026479367811332193\n",
      "  (0, 3861)\t0.037086118042498756\n",
      "  (0, 3127)\t0.045194792781563825\n",
      "  (0, 2706)\t0.03944779505015926\n",
      "  (0, 2497)\t0.04125298458168288\n",
      "  (0, 1638)\t0.030245141827680594\n",
      "  (0, 1205)\t0.026437855036625702\n",
      "  (0, 1194)\t0.015678567372955605\n",
      "  (0, 975)\t0.054384295002159716\n",
      "  (0, 456)\t0.02754582106583983\n",
      "  (0, 393)\t0.056590736756217126\n",
      "  (0, 1)\t0.018567429688079177\n",
      "['REAL']\n",
      "[1.46443568]\n"
     ]
    }
   ],
   "source": [
    "root = Tk()\n",
    "#Label 1\n",
    "label1 = Label(root,text = 'Article:')\n",
    "label1.pack()\n",
    "label1.config(justify = CENTER)\n",
    "\n",
    "entry1 = Text(root, width = 60, height = 10)\n",
    "entry1.pack()\n",
    "\n",
    "button1 = Button(root, text = 'Analyze')\n",
    "button1.pack() \n",
    "button1.config(command = lambda: analyze_article(entry1.get(\"1.0\",'end-1c')))\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
